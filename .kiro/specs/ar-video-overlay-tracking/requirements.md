# Requirements Document

## Introduction

This document specifies requirements for implementing a talking photo feature with lip-sync in the TalkAR Android application. The feature creates the illusion that a static poster is talking by overlaying only the lip region with synchronized video generated by Wav2Lip. The poster remains static while only the lips move, creating a natural talking effect. The system uses ARCore for real-time poster tracking, a backend service for lip-sync video generation, and alpha blending for seamless visual integration.

## Glossary

- **AR_System**: The ARCore-based augmented reality system that detects and tracks posters in real-time
- **Poster**: A physical image containing a human face that serves as the target for lip-sync overlay
- **Lip_Region**: The rectangular area containing only the lips, defined by normalized coordinates (lipX, lipY, lipWidth, lipHeight)
- **Lip_Video**: The video file containing only lip movements, generated by Wav2Lip and cropped by the backend
- **Backend_Service**: The server component that matches posters, generates lip-sync videos using Wav2Lip, and provides lip coordinates
- **Image_Anchor**: ARCore's tracking data for a detected poster, including position and orientation
- **Tracking_Update**: Position and orientation data from ARCore for a detected poster, provided at 60fps
- **Alpha_Blending**: The technique of feathering edges (5-10px Gaussian blur) to blend the Lip_Video naturally with the Poster
- **Normalized_Coordinates**: Coordinate values in the range 0-1, where (0,0) is top-left and (1,1) is bottom-right of the poster
- **Video_Cache**: Local storage for downloaded Lip_Videos with 24-hour retention
- **Wav2Lip**: The AI model used by the Backend_Service to generate lip-sync videos from audio and face images

## Requirements

### Requirement 1: Poster Detection and Tracking

**User Story:** As a user, I want the app to detect posters with human faces through my live camera feed, so that I can trigger the talking photo effect.

#### Acceptance Criteria

1. WHEN a Poster appears in the live camera view, THE AR_System SHALL detect it within 2 seconds
2. THE AR_System SHALL detect only Posters containing human faces, not products or mascots
3. WHEN a Poster is detected, THE AR_System SHALL create an Image_Anchor with position and orientation data
4. WHILE a Poster is visible, THE AR_System SHALL provide Tracking_Updates at 60 frames per second
5. THE AR_System SHALL use live camera feed for detection and tracking, not snapshots

### Requirement 2: Backend Poster Matching

**User Story:** As a user, I want the backend to identify which person or character is on the poster, so that the correct lip-sync content is generated.

#### Acceptance Criteria

1. WHEN a Poster is detected, THE Backend_Service SHALL receive the poster image for matching
2. THE Backend_Service SHALL identify the person or character on the Poster
3. WHEN the Poster is matched, THE Backend_Service SHALL return the associated audio content for lip-sync
4. IF the Poster cannot be matched, THEN THE Backend_Service SHALL return an error with a descriptive message
5. THE Backend_Service SHALL complete poster matching within 3 seconds

### Requirement 3: Lip-Sync Video Generation

**User Story:** As a content creator, I want the backend to generate realistic lip-sync videos, so that the talking photo effect looks natural.

#### Acceptance Criteria

1. WHEN a Poster is matched, THE Backend_Service SHALL generate a Lip_Video using Wav2Lip
2. THE Backend_Service SHALL crop the Wav2Lip output to the Lip_Region only before sending to mobile
3. THE Backend_Service SHALL provide Normalized_Coordinates for the Lip_Region (lipX, lipY, lipWidth, lipHeight)
4. THE Backend_Service SHALL generate Lip_Videos that synchronize with the provided audio content
5. WHEN generation completes, THE Backend_Service SHALL make the Lip_Video available for download

### Requirement 4: Lip Region Coordinate Format

**User Story:** As a developer, I want lip coordinates in a standard format, so that positioning is consistent across different poster sizes.

#### Acceptance Criteria

1. THE Backend_Service SHALL provide Lip_Region coordinates in Normalized_Coordinates format
2. THE Normalized_Coordinates SHALL use the range 0-1 where (0,0) is the top-left corner of the Poster
3. THE Backend_Service SHALL provide lipX, lipY, lipWidth, and lipHeight values
4. FOR ALL Posters, THE Normalized_Coordinates SHALL enable accurate Lip_Region positioning regardless of physical poster size
5. THE Backend_Service SHALL validate that all coordinate values are within the range 0-1

### Requirement 5: Video Caching and Offline Playback

**User Story:** As a user, I want downloaded lip-sync videos to be cached, so that I can view them offline after the first download.

#### Acceptance Criteria

1. WHEN a Lip_Video is downloaded, THE Video_Cache SHALL store it locally on the device
2. THE Video_Cache SHALL retain Lip_Videos for 24 hours from download time
3. WHEN a cached Lip_Video is requested, THE Video_Cache SHALL provide it without network access
4. WHEN a Lip_Video expires after 24 hours, THE Video_Cache SHALL delete it automatically
5. THE Video_Cache SHALL support offline playback of cached Lip_Videos

### Requirement 6: Single Poster Mode with Refresh

**User Story:** As a user, I want to focus on one poster at a time with the ability to scan a new one, so that the experience is simple and clear.

#### Acceptance Criteria

1. THE AR_System SHALL track only one Poster at a time
2. WHEN a Poster is being tracked, THE AR_System SHALL display a "Refresh Scan" button
3. WHEN the "Refresh Scan" button is pressed, THE AR_System SHALL clear the current Poster and allow scanning a new one
4. WHEN a new Poster is scanned, THE AR_System SHALL replace the previous Poster tracking
5. THE AR_System SHALL not attempt to track multiple Posters simultaneously

### Requirement 7: Real-Time Lip Overlay Positioning

**User Story:** As a user, I want the lip overlay to stay perfectly aligned with the poster as I move my camera, so that the effect looks realistic.

#### Acceptance Criteria

1. WHEN a Tracking_Update is received, THE AR_System SHALL update the Lip_Region position within the same frame (16ms at 60fps)
2. THE AR_System SHALL calculate Lip_Region position using the Normalized_Coordinates and current Poster dimensions
3. THE AR_System SHALL apply rotation and perspective transformation to match the Poster orientation in 3D space
4. FOR ALL Tracking_Updates at 60fps, THE AR_System SHALL maintain synchronization between Lip_Region and Poster position
5. THE AR_System SHALL use ARCore's transformation matrices for position calculations

### Requirement 8: Out of Frame Handling

**User Story:** As a user, I want clear feedback when the poster goes out of frame, so that I know to reposition my camera.

#### Acceptance Criteria

1. WHEN a Poster leaves the camera view, THE AR_System SHALL pause Lip_Video playback immediately
2. WHEN a Poster is out of frame, THE AR_System SHALL display the message "Align poster properly"
3. WHEN the Poster returns to the camera view, THE AR_System SHALL resume Lip_Video playback from the paused position
4. THE AR_System SHALL detect out-of-frame condition within one frame (16ms)
5. THE AR_System SHALL remove the "Align poster properly" message when the Poster is back in frame

### Requirement 9: Alpha Blending for Natural Appearance

**User Story:** As a user, I want the lip overlay to blend seamlessly with the poster, so that it looks like the poster is actually talking.

#### Acceptance Criteria

1. THE AR_System SHALL apply Alpha_Blending to the edges of the Lip_Region
2. THE Alpha_Blending SHALL use a Gaussian blur with 5-10 pixel feather radius
3. THE AR_System SHALL blend the Lip_Video with the static Poster to create a natural appearance
4. FOR ALL frames, THE Alpha_Blending SHALL maintain consistent edge quality without visible seams
5. THE AR_System SHALL render the blended result at 60fps without performance degradation

### Requirement 10: Static Poster with Moving Lips

**User Story:** As a user, I want only the lips to move while the rest of the poster stays static, so that it looks like a natural talking effect.

#### Acceptance Criteria

1. THE AR_System SHALL overlay only the Lip_Region on the Poster, not the full face
2. THE AR_System SHALL keep the Poster static and visible at all times during playback
3. THE Lip_Video SHALL contain only lip movements without surrounding facial features
4. FOR ALL frames, THE AR_System SHALL render the Lip_Region on top of the corresponding area of the Poster
5. THE AR_System SHALL create the visual effect that the Poster itself is talking

### Requirement 11: Backend API Integration

**User Story:** As a developer, I want to integrate with the existing backend API, so that I can leverage the lip-sync generation services.

#### Acceptance Criteria

1. THE AR_System SHALL call POST /api/lipsync/generate to request Lip_Video generation
2. THE AR_System SHALL poll GET /api/lipsync/status/{videoId} to check generation progress
3. WHEN generation is complete, THE AR_System SHALL download the Lip_Video from the provided URL
4. THE Backend_Service SHALL return Normalized_Coordinates along with the Lip_Video URL
5. IF any API call fails, THEN THE AR_System SHALL retry up to 3 times with exponential backoff

### Requirement 12: Budget Development Infrastructure

**User Story:** As a developer, I want to use free infrastructure for development, so that I can build and test without cost.

#### Acceptance Criteria

1. WHERE development environment, THE Backend_Service SHALL run on Google Colab with ngrok for free hosting
2. WHERE demo environment, THE Backend_Service SHALL run on Hugging Face Spaces for free public access
3. THE Backend_Service SHALL use Wav2Lip model for lip-sync generation
4. THE Backend_Service SHALL provide the same API interface across development and demo environments
5. THE Backend_Service SHALL handle concurrent requests within the free tier limitations

### Requirement 13: Video Format and Quality

**User Story:** As a user, I want high-quality lip-sync video, so that the talking effect looks realistic and smooth.

#### Acceptance Criteria

1. THE Backend_Service SHALL generate Lip_Videos in MP4 format with H.264 codec
2. THE Lip_Videos SHALL have a frame rate of at least 25fps for smooth lip movement
3. THE Lip_Videos SHALL have sufficient resolution to appear clear when overlaid on the Poster
4. THE Backend_Service SHALL synchronize Lip_Video frames with audio within 50ms accuracy
5. THE Lip_Videos SHALL maintain consistent quality across different poster sizes

### Requirement 14: Error Handling and User Feedback

**User Story:** As a user, I want clear error messages when something goes wrong, so that I know what to do next.

#### Acceptance Criteria

1. IF Poster detection fails after 10 seconds, THEN THE AR_System SHALL display "No poster detected. Try better lighting."
2. IF the Backend_Service is unavailable, THEN THE AR_System SHALL display "Service unavailable. Please try again later."
3. IF Lip_Video download fails, THEN THE AR_System SHALL retry download up to 3 times before showing an error
4. WHEN generation is in progress, THE AR_System SHALL display a progress indicator with estimated time
5. IF a Poster contains no human face, THEN THE AR_System SHALL display "Please scan a poster with a human face"

### Requirement 15: Resource Management and Performance

**User Story:** As a user, I want the app to run smoothly without draining my battery, so that I can use it for extended periods.

#### Acceptance Criteria

1. THE AR_System SHALL limit Video_Cache size to 500MB maximum
2. WHEN memory pressure occurs, THE AR_System SHALL delete oldest cached Lip_Videos first
3. THE AR_System SHALL release video decoder resources when Lip_Video playback is paused
4. THE AR_System SHALL maintain 60fps camera tracking and video rendering on devices with ARCore support
5. WHEN the app enters background, THE AR_System SHALL pause playback and release camera resources within 1 second

### Requirement 16: Lip-Sync Video Round-Trip Property

**User Story:** As a developer, I want to verify that lip-sync videos maintain integrity through the full pipeline, so that I can ensure no corruption occurs.

#### Acceptance Criteria

1. FOR ALL Lip_Videos, downloading then caching then retrieving SHALL produce identical video data
2. THE Backend_Service SHALL provide checksums for Lip_Videos to verify download integrity
3. WHEN a Lip_Video is cached, THE Video_Cache SHALL verify the checksum before storing
4. FOR ALL cached Lip_Videos, THE Video_Cache SHALL validate checksums before playback
5. IF checksum validation fails, THEN THE Video_Cache SHALL delete the corrupted file and re-download
