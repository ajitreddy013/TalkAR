# Implementation Plan: Talking Photo with Lip-Sync

## Overview

This implementation plan creates a talking photo feature with lip-sync for the TalkAR Android application. The system creates the illusion that a static poster is talking by overlaying only the lip region with synchronized video generated by Wav2Lip. The poster remains static while only the lips move, creating a natural talking effect.

### Solution Approach

The architecture consists of three main subsystems:

1. **Backend Wav2Lip Integration**: Backend service generates lip-sync videos using Wav2Lip, crops to lip region only, and provides normalized coordinates
2. **Real-Time AR Tracking**: ARCore detects posters with human faces and provides 60fps tracking updates in single poster mode
3. **Alpha Blending Rendering**: Mobile app blends lip video with static poster using Gaussian blur for natural appearance

### Key Components to Implement
- **TalkingPhotoController**: Orchestrates complete lifecycle from poster detection through video generation to playback
- **BackendVideoFetcher**: Manages communication with backend service for lip-sync video generation and download
- **VideoCache**: Manages local storage of downloaded lip-sync videos with 24-hour retention
- **VideoDecoder**: Decodes lip-sync video files using ExoPlayer (reused from Phase 1)
- **LipRegionRenderer**: Renders lip video with alpha blending for seamless integration
- **RenderCoordinator**: Synchronizes AR tracking updates with video rendering at 60fps
- **ARTrackingManager**: Manages ARCore poster detection with human face filter and single poster mode

### Phase 1 Status (Completed)

Phase 1 foundation work is complete and can be repurposed:
- ✅ VideoDecoder: Can decode lip videos
- ✅ TextureSurface: Can render lip region
- ✅ Data models: Need modification for lip coordinates
- ✅ 10 data model files created
- ✅ VideoError sealed class hierarchy created
- ✅ Unit tests for VideoDecoder created

### Implementation Strategy

The tasks are organized in dependency order across 5 phases, with checkpoints at strategic points. Property-based tests (marked with *) are optional for MVP but recommended for production. Each task references specific requirements from requirements.md for traceability.

## Tasks

### Phase 1: Foundation (Tasks 1-4) - COMPLETED ✅

- [x] 1. Set up core data models and error types
  - [x] 1.1 Create data models package structure
  - [x] 1.2 Implement core data classes
  - [x] 1.3 Implement PlaybackState enum
  - [x] 1.4 Create VideoError sealed class hierarchy
  - [x] 1.5 Create VideoMetrics data class

- [x] 2. Implement TextureSurface component
  - [x] 2.1 Create TextureSurface interface and implementation
  - [x] 2.2 Create Composable wrapper for TextureSurface

- [x] 3. Implement VideoDecoder component
  - [x] 3.1 Create VideoDecoder interface and ExoPlayer-based implementation
  - [x] 3.2 Implement video dimension extraction with fallback
  - [x] 3.4 Implement decoder initialization with retry logic

- [x] 4. Checkpoint - Verify decoder and surface components
  - [x] 4.1 Run all TextureSurface and VideoDecoder unit tests
  - [x] 4.2 Verify dimension extraction works with test video file
  - [x] 4.3 Confirm surface lifecycle management handles recreation correctly
  - [x] 4.4 Test ExoPlayer initialization and track detection
  - [x] 4.5 Verify hardware acceleration is enabled


### Phase 2: Lip-Sync Data Models & Backend Integration (Tasks 5-9)

- [x] 5. Update data models for lip-sync
  - [x] 5.1 Create LipCoordinates data class
    - Add lipX, lipY, lipWidth, lipHeight fields (Float, 0-1 range)
    - Add validation in init block to ensure 0-1 range
    - Add toPixelCoordinates() method for conversion
    - _Requirements: 3.3, 4.1, 4.2, 4.3, 4.4, 4.5_
  
  - [x] 5.2 Create TalkingPhotoState enum
    - Define states: IDLE, FETCHING_VIDEO, GENERATING, DOWNLOADING, READY, PLAYING, PAUSED, ERROR
    - _Requirements: 14.4_
  
  - [x] 5.3 Create TalkingPhotoError sealed class
    - PosterNotDetected, BackendUnavailable, GenerationFailed
    - DownloadFailed, InvalidCoordinates, CacheCorrupted, NoHumanFace
    - Include error codes (2001-2007) and contextual information
    - _Requirements: 14.1, 14.2, 14.3, 14.5_
  
  - [x] 5.4 Create backend API data models
    - TalkingPhotoRequest (posterId, text, voiceId)
    - GenerateResponse (videoId, status)
    - StatusResponse (videoId, status, progress, videoUrl, lipCoordinates, errorMessage)
    - LipCoordinatesDto (lipX, lipY, lipWidth, lipHeight)
    - _Requirements: 11.1, 11.2_
  
  - [x] 5.5 Create TalkingPhotoSession data class
    - Add posterId, anchorId, state, lipCoordinates, videoPath
    - Add isTracking, lastUpdateTimestamp, tracking frame counters
    - Implement shouldPause() and shouldResume() methods
    - _Requirements: 8.1, 8.3_
  
  - [x] 5.6 Write property test for coordinate validation
    - **Property 5: Normalized Coordinate Completeness and Range**
    - **Validates: Requirements 3.3, 4.1, 4.3, 4.5**
    - Test that all coordinate values are in 0-1 range

- [x] 6. Implement BackendVideoFetcher component
  - [x] 6.1 Create BackendVideoFetcher interface and implementation
    - Implement generateLipSync() to call POST /api/lipsync/generate
    - Implement checkStatus() to poll GET /api/lipsync/status/{videoId}
    - Implement downloadVideo() with progress callback
    - Implement cancel() for ongoing operations
    - _Requirements: 11.1, 11.2, 11.3_
  
  - [x] 6.2 Implement exponential backoff retry logic
    - Retry up to 3 times with delays: 1s, 2s, 4s
    - Log each retry attempt
    - Return failure after max retries
    - _Requirements: 11.5, 14.3_
  
  - [x] 6.3 Write property test for retry logic
    - **Property 22: API Retry with Exponential Backoff**
    - **Validates: Requirements 11.5, 14.3**
    - Test that failed API calls retry 3 times with exponential delays
  
  - [x] 6.4 Implement status polling
    - Poll every 2 seconds until status is "complete" or "failed"
    - Provide progress updates via callback
    - Handle timeout after 60 seconds
    - _Requirements: 11.2_
  
  - [x]* 6.5 Write property test for status polling
    - **Property 21: Status Polling Until Complete**
    - **Validates: Requirements 11.2**
    - Test that polling continues until status changes to complete/failed
  
  - [x] 6.6 Implement coordinate validation
    - Validate lipCoordinates are in 0-1 range
    - Return InvalidCoordinates error if validation fails
    - _Requirements: 4.5_
  
  - [x] 6.7 Add Retrofit API service
    - Define API endpoints with Retrofit annotations
    - Configure OkHttp with logging interceptor
    - Set timeouts (connect: 10s, read: 60s, write: 60s)
    - _Requirements: 11.1, 11.2_


- [x] 7. Implement VideoCache component
  - [x] 7.1 Create VideoCache interface and implementation
    - Implement store() to save video with metadata
    - Implement retrieve() to get cached video if not expired
    - Implement isCached() to check availability
    - Implement validateIntegrity() for checksum validation
    - Implement cleanupExpired() to delete old videos
    - Implement enforceLimit() for 500MB cache limit
    - _Requirements: 5.1, 5.2, 5.3, 5.4, 15.1_
  
  - [x] 7.2 Implement SQLite database for cache metadata
    - Create CacheEntry entity (posterId, videoPath, lipCoordinates, checksum, cachedAt, sizeBytes)
    - Create CacheDao with insert, get, getAll, delete operations
    - Use Room database library
    - _Requirements: 5.1_
  
  - [x] 7.3 Implement checksum calculation and validation
    - Use SHA-256 for checksum calculation
    - Validate checksum before storing
    - Validate checksum before retrieving
    - Delete corrupted files automatically
    - _Requirements: 16.1, 16.2, 16.3, 16.4, 16.5_
  
  - [x]* 7.4 Write property test for cache round-trip
    - **Property 31: Video Cache Round-Trip**
    - **Validates: Requirements 16.1**
    - Test that download-cache-retrieve produces identical data
  
  - [x]* 7.5 Write property test for checksum validation
    - **Property 32: Checksum Validation and Recovery**
    - **Validates: Requirements 16.2, 16.3, 16.4, 16.5**
    - Test that checksums are validated and corrupted files trigger re-download
  
  - [x] 7.6 Implement 24-hour expiration
    - Check cachedAt timestamp on retrieval
    - Delete expired videos automatically
    - _Requirements: 5.2, 5.4_
  
  - [x]* 7.7 Write property test for expiration
    - **Property 8: Cache Expiration**
    - **Validates: Requirements 5.2, 5.4**
    - Test that videos >24 hours old are not returned and marked for deletion
  
  - [x] 7.8 Implement LRU eviction for 500MB limit
    - Calculate total cache size
    - Delete oldest videos when limit exceeded
    - Continue until under 500MB
    - _Requirements: 15.1, 15.2_
  
  - [x]* 7.9 Write property tests for cache limits
    - **Property 27: Cache Size Limit**
    - **Validates: Requirements 15.1**
    - **Property 28: LRU Eviction Order**
    - **Validates: Requirements 15.2**
    - Test that cache never exceeds 500MB and oldest videos are deleted first

- [x] 8. Implement offline cache retrieval
  - [x] 8.1 Add cache-first strategy
    - Check cache before making backend request
    - Return cached video immediately if available
    - Only call backend if cache miss
    - _Requirements: 5.3, 5.5_
  
  - [x]* 8.2 Write property test for offline retrieval
    - **Property 9: Offline Cache Retrieval**
    - **Validates: Requirements 5.3, 5.5**
    - Test that cached videos are retrieved without network requests
  
  - [x]* 8.3 Write property test for cache hit
    - **Property 7: Video Caching on Download**
    - **Validates: Requirements 5.1**
    - Test that downloaded videos appear in cache immediately

- [x] 9. Checkpoint - Verify backend integration and caching
  - [x] 9.1 Test BackendVideoFetcher with mock backend
  - [x] 9.2 Verify retry logic with exponential backoff
  - [x] 9.3 Test VideoCache store and retrieve operations
  - [x] 9.4 Verify checksum validation catches corrupted files
  - [x] 9.5 Test 24-hour expiration and LRU eviction
  - [x] 9.6 Confirm offline cache retrieval works without network
  - Ask the user if questions arise or if ready to proceed to Phase 3


### Phase 3: AR Tracking & Rendering (Tasks 10-14)

- [ ] 10. Implement ARTrackingManager component
  - [x] 10.1 Create ARTrackingManager interface and implementation
    - Implement initialize() with AugmentedImageDatabase setup
    - Implement processFrame() to detect and track posters
    - Implement getCurrentAnchor() for anchor retrieval
    - Implement refreshScan() to clear current poster and allow new scan
    - Implement release() for resource cleanup
    - _Requirements: 1.1, 1.2, 1.3, 1.4, 6.1, 6.2, 6.3, 6.4_
  
  - [ ] 10.2 Implement single poster mode
    - Track only one poster at a time
    - Ignore other posters when one is already tracked
    - Clear tracking when refreshScan() is called
    - _Requirements: 6.1, 6.4, 6.5_
  
  - [ ]* 10.3 Write property test for single poster mode
    - **Property 10: Single Poster Tracking**
    - **Validates: Requirements 6.1, 6.5**
    - Test that at most one poster is tracked when multiple are visible
  
  - [ ]* 10.4 Write property test for poster replacement
    - **Property 11: Poster Replacement**
    - **Validates: Requirements 6.4**
    - Test that new poster replaces previous when scanned
  
  - [ ] 10.5 Implement human face detection filter
    - Check poster metadata for human face indicator
    - Only detect posters marked as containing human faces
    - Reject products and mascots
    - _Requirements: 1.2, 14.5_
  
  - [ ]* 10.6 Write property test for face detection filter
    - **Property 1: Human Face Detection Filter**
    - **Validates: Requirements 1.2**
    - Test that only posters with human faces are detected
  
  - [ ] 10.7 Implement 60fps tracking updates
    - Provide tracking updates at camera frame rate
    - Use ARCore's frame callback mechanism
    - _Requirements: 1.4, 7.1_
  
  - [ ] 10.8 Implement out-of-frame detection
    - Detect when poster leaves camera view
    - Trigger onPosterLost() callback
    - Resume tracking when poster returns
    - _Requirements: 8.1, 8.2, 8.3_
  
  - [ ]* 10.9 Write property test for anchor creation
    - **Property 2: Anchor Creation on Detection**
    - **Validates: Requirements 1.3**
    - Test that detected posters create anchors with valid position/orientation

- [ ] 11. Implement RenderCoordinator component
  - [ ] 11.1 Create RenderCoordinator interface and implementation
    - Implement calculateTransform() with ARCore matrix math
    - Use Camera.getProjectionMatrix() and Camera.getViewMatrix()
    - Convert 3D anchor pose to 2D screen coordinates
    - Calculate scale based on distance from camera
    - Implement frustum culling for off-screen overlays
    - _Requirements: 7.1, 7.2, 7.3, 7.4_
  
  - [ ] 11.2 Implement normalized coordinate conversion
    - Convert LipCoordinates (0-1 range) to pixel coordinates
    - Use poster dimensions from ARCore
    - Handle different poster sizes and orientations
    - _Requirements: 4.4, 7.2_
  
  - [ ]* 11.3 Write property test for coordinate conversion
    - **Property 6: Coordinate Scaling Consistency**
    - **Validates: Requirements 4.4**
    - **Property 12: Coordinate to Pixel Conversion**
    - **Validates: Requirements 7.2**
    - Test that normalized-to-pixel-to-normalized produces original values
  
  - [ ] 11.4 Implement frame callback synchronization
    - Register frame callbacks with Choreographer
    - Provide 60fps updates
    - Calculate frame delta times
    - _Requirements: 7.1, 7.4_
  
  - [ ] 11.5 Implement transform caching
    - Cache projection and view matrices per frame
    - Reuse calculations for efficiency
    - Implement dirty flags to avoid unnecessary recalculations
    - _Requirements: 7.4_
  
  - [ ]* 11.6 Write property test for transform calculation
    - **Property 13: Transform Application**
    - **Validates: Requirements 7.3**
    - Test that transforms correctly position and orient lip region


- [ ] 12. Implement LipRegionRenderer component
  - [ ] 12.1 Create LipRegionRenderer interface and implementation
    - Implement setLipCoordinates() to set normalized coordinates
    - Implement setPosterDimensions() for coordinate conversion
    - Implement setTransform() to apply AR tracking matrix
    - Implement setBlendingParameters() for feather radius
    - Implement getSurface() to provide Surface for VideoDecoder
    - Implement setVisible() and release()
    - _Requirements: 9.1, 9.2, 9.3, 9.4, 10.1, 10.2, 10.4_
  
  - [ ] 12.2 Implement alpha blending shader
    - Create OpenGL vertex and fragment shaders
    - Implement Gaussian blur for edge feathering (5-10px)
    - Blend lip video with static poster background
    - Use smoothstep for smooth alpha transition
    - _Requirements: 9.1, 9.2, 9.3_
  
  - [ ]* 12.3 Write property test for alpha blending
    - **Property 16: Alpha Blending Application**
    - **Validates: Requirements 9.1**
    - **Property 17: Feather Radius Range**
    - **Validates: Requirements 9.2**
    - Test that edge pixels have alpha 0-1 and feather radius is 5-10px
  
  - [ ] 12.4 Implement TextureView integration
    - Use TextureView from Phase 1
    - Configure for lip region rendering
    - Apply transformations via Matrix operations
    - _Requirements: 10.1, 10.2_
  
  - [ ] 12.5 Implement lip region only rendering
    - Render only lip region, not full face
    - Keep poster static and visible
    - Layer lip region on top of poster
    - _Requirements: 10.1, 10.2, 10.3, 10.4_
  
  - [ ]* 12.6 Write property tests for lip region rendering
    - **Property 18: Lip Region Only Rendering**
    - **Validates: Requirements 10.1**
    - **Property 19: Poster Visibility During Playback**
    - **Validates: Requirements 10.2**
    - **Property 20: Lip Region Layering**
    - **Validates: Requirements 10.4**
    - Test that only lip region is rendered and poster stays visible
  
  - [ ] 12.7 Optimize for 60fps rendering
    - Use hardware acceleration
    - Minimize shader complexity
    - Cache shader programs
    - Profile rendering performance
    - _Requirements: 9.4, 15.4_

- [ ] 13. Implement video format validation
  - [ ] 13.1 Validate MP4 format with H.264 codec
    - Check video container format
    - Verify codec is H.264
    - _Requirements: 13.1_
  
  - [ ]* 13.2 Write property test for format validation
    - **Property 24: Video Format Validation**
    - **Validates: Requirements 13.1**
    - Test that downloaded videos are MP4 with H.264
  
  - [ ] 13.3 Validate minimum frame rate
    - Check video frame rate is ≥25fps
    - Log warning if frame rate is low
    - _Requirements: 13.2_
  
  - [ ]* 13.4 Write property test for frame rate
    - **Property 25: Minimum Frame Rate**
    - **Validates: Requirements 13.2**
    - Test that videos have ≥25fps
  
  - [ ] 13.5 Validate audio-video synchronization
    - Check frame timestamps align with audio within 50ms
    - Monitor sync drift during playback
    - _Requirements: 13.4_
  
  - [ ]* 13.6 Write property test for A/V sync
    - **Property 26: Audio-Video Synchronization**
    - **Validates: Requirements 13.4**
    - Test that frame and audio timestamps align within 50ms

- [ ] 14. Checkpoint - Verify tracking and rendering
  - [ ] 14.1 Test ARTrackingManager with mock ARCore data
  - [ ] 14.2 Verify single poster mode works correctly
  - [ ] 14.3 Test human face detection filter
  - [ ] 14.4 Verify RenderCoordinator transform calculations
  - [ ] 14.5 Test LipRegionRenderer alpha blending
  - [ ] 14.6 Confirm 60fps rendering performance
  - [ ] 14.7 Test out-of-frame detection and recovery
  - Ask the user if questions arise or if ready to proceed to Phase 4


### Phase 4: Orchestration & UI (Tasks 15-19)

- [ ] 15. Implement TalkingPhotoController component
  - [ ] 15.1 Create TalkingPhotoController interface and implementation
    - Implement initialize() to set up for detected poster
    - Implement updateTracking() to process ARCore tracking data
    - Implement play(), pause(), stop() playback controls
    - Implement getState() for state machine management
    - Implement release() for resource cleanup
    - Implement setCallbacks() for lifecycle events
    - _Requirements: 1.1, 2.1, 2.2, 8.1, 8.3_
  
  - [ ] 15.2 Implement state machine
    - Define state transitions: IDLE → FETCHING_VIDEO → GENERATING → DOWNLOADING → READY → PLAYING → PAUSED → ERROR
    - Handle state changes based on events
    - Validate state transitions
    - _Requirements: 14.4_
  
  - [ ] 15.3 Orchestrate component interactions
    - Coordinate BackendVideoFetcher, VideoCache, VideoDecoder, LipRegionRenderer
    - Manage component lifecycle
    - Handle errors from any component
    - _Requirements: 2.1, 2.2, 11.1, 11.2, 11.3_
  
  - [ ]* 15.4 Write property test for backend request trigger
    - **Property 3: Backend Request on Detection**
    - **Validates: Requirements 2.1**
    - Test that poster detection triggers backend API request
  
  - [ ] 15.5 Implement tracking update handling
    - Process tracking updates at 60fps
    - Calculate transforms via RenderCoordinator
    - Apply transforms to LipRegionRenderer
    - Record update timestamps for latency tracking
    - _Requirements: 7.1, 7.4_
  
  - [ ] 15.6 Implement pause on tracking loss
    - Pause video playback when poster goes out of frame
    - Save current playback position
    - Trigger onTrackingLost() callback
    - _Requirements: 8.1_
  
  - [ ]* 15.7 Write property test for pause on tracking loss
    - **Property 14: Playback Pause on Tracking Loss**
    - **Validates: Requirements 8.1**
    - Test that playback pauses immediately when tracking is lost
  
  - [ ] 15.8 Implement resume on tracking recovery
    - Resume playback when poster returns to frame
    - Resume from saved position, not from beginning
    - Trigger onTrackingResumed() callback
    - _Requirements: 8.3_
  
  - [ ]* 15.9 Write property test for resume from position
    - **Property 15: Playback Resume from Position**
    - **Validates: Requirements 8.3**
    - Test that playback resumes from paused position
  
  - [ ] 15.10 Implement resource management
    - Release decoder resources when paused
    - Release camera resources when app goes to background
    - Clean up on controller release
    - _Requirements: 15.3, 15.5_
  
  - [ ]* 15.11 Write property tests for resource management
    - **Property 29: Resource Release on Pause**
    - **Validates: Requirements 15.3**
    - **Property 30: Background Resource Release**
    - **Validates: Requirements 15.5**
    - Test that resources are released appropriately

- [ ] 16. Implement UI components with Compose
  - [ ] 16.1 Create TalkingPhotoScreen Composable
    - Integrate ArSceneView for AR camera
    - Add LipRegionOverlay for video rendering
    - Add state-based UI overlays
    - Handle Compose lifecycle
    - _Requirements: 1.1, 8.2, 14.1, 14.2, 14.4_
  
  - [ ] 16.2 Create progress indicators
    - GeneratingIndicator with progress bar and percentage
    - DownloadingIndicator with progress bar
    - Show estimated time remaining
    - _Requirements: 14.4_
  
  - [ ] 16.3 Create "Align poster properly" message
    - Display when poster is out of frame
    - Use Card with warning icon
    - Auto-hide when tracking resumes
    - _Requirements: 8.2_
  
  - [ ] 16.4 Create "Refresh Scan" button
    - Display when poster is being tracked
    - Call refreshScan() on click
    - Position at bottom center
    - _Requirements: 6.2, 6.3_
  
  - [ ] 16.5 Create error message displays
    - Show user-friendly error messages
    - Map error codes to messages
    - Provide retry options where appropriate
    - _Requirements: 14.1, 14.2, 14.3, 14.5_
  
  - [ ] 16.6 Create scanning instruction text
    - Display "Point camera at a poster with a human face" when idle
    - Clear instructions for user
    - _Requirements: 1.1, 1.2_


- [ ] 17. Implement error handling
  - [ ] 17.1 Handle poster detection errors
    - Timeout after 10 seconds: "No poster detected. Try better lighting."
    - No human face: "Please scan a poster with a human face"
    - _Requirements: 14.1, 14.5_
  
  - [ ] 17.2 Handle backend communication errors
    - Backend unavailable: "Service unavailable. Please try again later."
    - Network timeout: Retry with exponential backoff
    - API rate limiting: Display wait time
    - _Requirements: 14.2_
  
  - [ ] 17.3 Handle video generation errors
    - Generation failed: Display error with retry option
    - Invalid coordinates: Log error and retry
    - Unsupported format: Display error message
    - _Requirements: 14.3_
  
  - [ ] 17.4 Handle download errors
    - Network interruption: Retry up to 3 times
    - Insufficient storage: "Storage full. Clear some space."
    - Corrupted download: Validate checksum and retry
    - _Requirements: 14.3_
  
  - [ ] 17.5 Handle cache errors
    - Cache corrupted: Delete and re-download automatically
    - Checksum validation failed: Delete and re-download
    - Storage full: Enforce cache limit with LRU eviction
    - _Requirements: 16.5_
  
  - [ ] 17.6 Implement error logging strategy
    - Log all errors with error code, timestamp, component, context
    - Include stack traces for exceptions
    - Use structured logging format
    - _Requirements: 14.1, 14.2, 14.3, 14.5_
  
  - [ ] 17.7 Map error codes to user messages
    - Create error message mapping table
    - Provide clear, actionable messages
    - Include retry options where appropriate
    - _Requirements: 14.1, 14.2, 14.3, 14.5_

- [ ] 18. Implement backend API configuration
  - [ ] 18.1 Configure development environment (Google Colab + ngrok)
    - Set base URL from environment variable
    - Support dynamic ngrok URLs
    - _Requirements: 12.1_
  
  - [ ] 18.2 Configure demo environment (Hugging Face Spaces)
    - Set base URL for HF Spaces
    - Handle free tier limitations
    - _Requirements: 12.2_
  
  - [ ] 18.3 Ensure API interface consistency
    - Same endpoints across environments
    - Same request/response formats
    - Same error handling
    - _Requirements: 12.4_
  
  - [ ]* 18.4 Write property test for API consistency
    - **Property 23: API Interface Consistency**
    - **Validates: Requirements 12.4**
    - Test that API interface is identical across environments

- [ ] 19. Checkpoint - Verify complete system integration
  - [ ] 19.1 Test complete flow: Detection → Generation → Download → Cache → Playback
  - [ ] 19.2 Test cache hit scenario: Detection → Cache retrieval → Playback
  - [ ] 19.3 Test tracking loss and recovery
  - [ ] 19.4 Test "Refresh Scan" functionality
  - [ ] 19.5 Test all error scenarios and user messages
  - [ ] 19.6 Verify state transitions work correctly
  - [ ] 19.7 Test resource cleanup on app background
  - Ask the user if questions arise or if ready to proceed to Phase 5


### Phase 5: Testing & Optimization (Tasks 20-23)

- [ ] 20. Write comprehensive property-based tests
  - [ ] 20.1 Set up Kotest Property Testing framework
    - Add Kotest dependencies to build.gradle
    - Configure test runners
    - Create custom generators (Arb.lipCoordinates(), Arb.posterDimensions(), etc.)
    - _All Requirements_
  
  - [ ] 20.2 Write remaining property tests
    - Property 4: Cropped Video Dimensions (Requirement 3.2)
    - Property 19: Poster Visibility During Playback (Requirement 10.2)
    - Property 20: Lip Region Layering (Requirement 10.4)
    - All other properties not yet covered
    - _All Requirements_
  
  - [ ] 20.3 Configure property test execution
    - Set minimum 100 iterations per test
    - Add property tags for traceability
    - Configure timeout and resource limits
    - _All Requirements_
  
  - [ ] 20.4 Run all 32 property tests
    - Verify all properties pass
    - Fix any failures
    - Document any edge cases found
    - _All Requirements_

- [ ] 21. Write comprehensive unit tests
  - [ ] 21.1 Write unit tests for TalkingPhotoController
    - Test state machine transitions
    - Test component orchestration
    - Test error handling
    - Test tracking update handling
    - _Requirements: 1.1, 2.1, 2.2, 8.1, 8.3_
  
  - [ ] 21.2 Write unit tests for BackendVideoFetcher
    - Test API calls with mock backend
    - Test retry logic
    - Test status polling
    - Test download with progress
    - _Requirements: 11.1, 11.2, 11.3, 11.5_
  
  - [ ] 21.3 Write unit tests for VideoCache
    - Test store and retrieve operations
    - Test expiration logic
    - Test checksum validation
    - Test LRU eviction
    - _Requirements: 5.1, 5.2, 5.3, 5.4, 15.1, 15.2_
  
  - [ ] 21.4 Write unit tests for ARTrackingManager
    - Test single poster mode
    - Test human face filter
    - Test refresh scan
    - Test out-of-frame detection
    - _Requirements: 1.1, 1.2, 1.3, 1.4, 6.1, 6.2, 6.3, 6.4_
  
  - [ ] 21.5 Write unit tests for RenderCoordinator
    - Test transform calculations
    - Test coordinate conversion
    - Test frustum culling
    - _Requirements: 4.4, 7.1, 7.2, 7.3, 7.4_
  
  - [ ] 21.6 Write unit tests for LipRegionRenderer
    - Test alpha blending shader
    - Test coordinate setting
    - Test transform application
    - _Requirements: 9.1, 9.2, 9.3, 9.4, 10.1, 10.2, 10.4_
  
  - [ ] 21.7 Write integration tests
    - Test end-to-end flow with real ARCore
    - Test cache hit scenario
    - Test tracking loss and recovery
    - Test refresh scan
    - _All Requirements_

- [ ] 22. Performance optimization
  - [ ] 22.1 Optimize cache operations
    - Preload poster database at app startup
    - Batch cache cleanup operations
    - Use background threads for I/O
    - _Requirements: 15.1, 15.2_
  
  - [ ] 22.2 Optimize rendering
    - Enable hardware acceleration for TextureView
    - Cache shader programs
    - Optimize alpha blending shader for low-end devices
    - Profile rendering performance
    - _Requirements: 9.4, 15.4_
  
  - [ ] 22.3 Optimize transform calculations
    - Cache projection and view matrices per frame
    - Reuse calculations for efficiency
    - Implement dirty flags
    - _Requirements: 7.4_
  
  - [ ] 22.4 Measure and verify performance metrics
    - Poster detection time (target: <2 seconds)
    - Cache retrieval time (target: <100ms)
    - Frame rate during playback (target: 60fps)
    - Tracking update latency (target: <16ms per frame)
    - _Requirements: 1.1, 7.1, 7.4, 15.4_
  
  - [ ] 22.5 Optimize for low-end devices
    - Reduce shader precision on low-end devices
    - Adjust quality settings based on device capabilities
    - Monitor battery usage
    - _Requirements: 15.4_

- [ ] 23. Final testing and documentation
  - [ ] 23.1 Run complete test suite
    - Run all unit tests
    - Run all property tests (32 properties)
    - Run all integration tests
    - Verify >80% code coverage
    - _All Requirements_
  
  - [ ] 23.2 Test on physical Android devices
    - Test on API 24+ devices
    - Test on different screen sizes
    - Test on low-end and high-end devices
    - Test with different posters
    - _All Requirements_
  
  - [ ] 23.3 Verify all requirements satisfied
    - Check all 16 requirements
    - Verify all acceptance criteria
    - Document any limitations
    - _All Requirements_
  
  - [ ] 23.4 Performance testing
    - Measure poster detection time
    - Measure cache retrieval time
    - Measure frame rate during playback
    - Measure tracking latency
    - Verify all metrics meet targets
    - _Requirements: 1.1, 7.1, 7.4, 15.4_
  
  - [ ] 23.5 Create user documentation
    - Document how to use talking photo feature
    - Document "Refresh Scan" button
    - Document error messages and solutions
    - Create troubleshooting guide
    - _All Requirements_
  
  - [ ] 23.6 Create developer documentation
    - Document architecture and components
    - Document API integration
    - Document testing strategy
    - Document performance optimization tips
    - _All Requirements_
  
  - [ ] 23.7 Final checkpoint
    - All tests passing
    - All requirements satisfied
    - Performance metrics met
    - Documentation complete
    - Ready for production
    - Ask the user for final review and approval


## Success Criteria

The implementation is complete when:

1. ✅ Posters with human faces are detected within 2 seconds
2. ✅ Backend generates lip-sync videos with Wav2Lip and crops to lip region only
3. ✅ Lip coordinates are provided in normalized format (0-1 range)
4. ✅ Videos are cached for 24 hours with checksum validation
5. ✅ Offline playback works after first download
6. ✅ Single poster mode with "Refresh Scan" button works
7. ✅ Lip region overlays on poster with alpha blending at 60fps
8. ✅ Out-of-frame handling pauses video and shows "Align poster properly"
9. ✅ Tracking resumes playback from paused position
10. ✅ All 16 requirements have passing acceptance criteria
11. ✅ All 32 correctness properties pass
12. ✅ Performance metrics meet targets (2s detection, <100ms cache, 60fps rendering, <16ms latency)
13. ✅ Integration tests pass for complete talking photo flow
14. ✅ Error handling works for all 7 error categories
15. ✅ Resource management properly releases resources

## Notes

### Testing Strategy

- **Property-based tests**: Validate universal correctness properties (32 total)
- **Unit tests**: Validate specific examples, edge cases, and integration points
- **Integration tests**: Test complete end-to-end flows with ARCore
- **Performance tests**: Measure and verify all critical metrics

### Implementation Guidelines

- **Language**: All code in Kotlin for Android
- **Video Library**: ExoPlayer (Media3) for video decoding
- **AR Library**: ARCore for poster detection and tracking
- **Backend**: Wav2Lip on Google Colab (dev) or Hugging Face Spaces (demo)
- **Target Platform**: Android API level 24 (Android 7.0) and above
- **Performance Target**: 60fps rendering with <16ms tracking latency
- **Cache Limit**: 500MB with 24-hour retention
- **Retry Strategy**: 3 attempts with exponential backoff (1s, 2s, 4s)

### Task Organization

- **Phase 1 (Tasks 1-4)**: Foundation - COMPLETED ✅
- **Phase 2 (Tasks 5-9)**: Lip-Sync Data Models & Backend Integration
- **Phase 3 (Tasks 10-14)**: AR Tracking & Rendering
- **Phase 4 (Tasks 15-19)**: Orchestration & UI
- **Phase 5 (Tasks 20-23)**: Testing & Optimization

### Traceability

- Each task references specific requirements from requirements.md
- Property tests reference specific correctness properties from design.md
- Checkpoints ensure incremental validation at phase boundaries

### File Locations

- **Source**: `mobile-app/app/src/main/java/com/talkar/app/ar/`
- **Models**: `mobile-app/app/src/main/java/com/talkar/app/ar/video/models/`
- **Tests**: `mobile-app/app/src/test/java/com/talkar/app/ar/video/`
- **API Client**: `mobile-app/app/src/main/java/com/talkar/app/data/api/ApiClient.kt`
- **Backend**: `backend/src/services/enhancedLipSyncService.ts`

### Critical Implementation Notes

1. **Normalized Coordinates**: Always validate that lipX, lipY, lipWidth, lipHeight are in 0-1 range
2. **Checksum Validation**: Always validate checksums before caching and before playback
3. **Single Poster Mode**: Only track one poster at a time, ignore others
4. **Tracking Loss**: Pause immediately when poster goes out of frame, resume from saved position
5. **Resource Management**: Release decoder when paused, release camera when app goes to background
6. **Cache Limits**: Enforce 500MB limit strictly with LRU eviction
7. **Retry Logic**: Retry up to 3 times with exponential backoff (1s, 2s, 4s)
8. **Alpha Blending**: Use 5-10px Gaussian blur for feathered edges
9. **60fps Rendering**: Use Choreographer for frame-synchronized updates
10. **Human Face Filter**: Only detect posters marked as containing human faces

### Repurposed Phase 1 Components

From the completed Phase 1 foundation:
- **VideoDecoder**: Can decode lip videos ✅
- **TextureSurface**: Can render lip region ✅
- **Data models**: Need modification for lip coordinates (Task 5)

### Backend API Endpoints

- **POST /api/lipsync/generate**: Generate lip-sync video
- **GET /api/lipsync/status/{videoId}**: Check generation status
- **GET {videoUrl}**: Download generated video

### Common Pitfalls to Avoid

1. Don't forget to validate normalized coordinates (0-1 range)
2. Don't skip checksum validation
3. Don't block the main thread (use coroutines for network/I/O)
4. Don't forget to release resources
5. Don't ignore tracking state changes
6. Don't exceed cache limits
7. Don't retry indefinitely (max 3 attempts)

### Performance Optimization Tips

1. Preload poster database at app startup
2. Use hardware acceleration for TextureView
3. Optimize alpha blending shader for low-end devices
4. Cache transform calculations per frame
5. Batch cache cleanup operations

## Summary

This implementation plan transforms the AR video overlay feature into a talking photo with lip-sync by:

1. **Backend Integration**: Using Wav2Lip on Google Colab/Hugging Face Spaces for video generation
2. **Efficient Caching**: 24-hour cache with checksum validation and LRU eviction
3. **Real-Time Tracking**: 60fps ARCore tracking with single poster mode
4. **Seamless Blending**: Alpha blending with Gaussian blur for natural appearance
5. **Robust Error Handling**: Retry logic, checksum validation, and graceful degradation
6. **Comprehensive Testing**: Property-based tests for all 32 correctness properties

The architecture prioritizes user experience with fast cache retrieval, clear error messages, and smooth 60fps rendering while maintaining resource efficiency through proper lifecycle management and cache limits.
